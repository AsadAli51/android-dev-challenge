# android-dev-challenge
 *Please make a copy of this document and include this in your GitHub repository for your submission, using the tag #AndroidDevChallenge*  Tell us what your idea is.   Basically my idea is to use the front camera of Smartphones to record the lips movements by showing the alphabets on screen and making a person record pronouncing the alphabet on screen 20 times. These inputs can then be stored in the form of matrix and apply neural network. Now real-time inputs can be given to the neural network and based on this neural network can decide which letter or word you are saying.    Tell us how you plan on bringing it to life.   Capturing images once i will train the neural network to select exact alphabet for the lip movement. Once it is done then i can use it while recording the video and making matrix of pronouncing combination of words. Neural network itself is learning and now it can break a video  and look for word combinations.Now the device will be able to understand what you are saying.  (1) I have a code of reading eyeball movements but not of understanding lips movements.   ,  (2) Google can help me financially and support me by letting me work the staff of google.,  (3) I can do this if i am supported by January 1, 2020.     Tell us about you.   I am an avionics engineer graduated from NUST. The code for detecting eyeball movements is attached.    Next steps.   Create my workstation and get some time out of my job to spend it t write the code   Be sure to include this cover letter in your GitHub repository Your GitHub repository should be tagged #AndroidDevChallenge Donâ€™t forget to include other items in your GitHub repository to help us evaluate your submission; you can include prior projects you've worked on, sample code you've already built for this project, or anything else you think could be helpful in evaluating your concept and your ability to build it The final step is to fill out this form to officially submit your proposal. 
